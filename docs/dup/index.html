<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="icon" href="../logo.svg">
<link rel="stylesheet" href="../tango.css" type="text/css">
<link rel="stylesheet" href="../mccole.css" type="text/css">
<title>Software Design by Example &middot; Finding Duplicate Files</title>
<script>
  MathJax = {
    tex: {
      inlineMath: [['\\(', '\\)']]
    }
  };
</script>
<script
  type="text/javascript"
  id="MathJax-script"
  async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


  </head>
  <body>
    <div class="row">
      <div class="sidebar">
        <p>
  
  <a href="https://www.routledge.com/Software-Design-by-Example-A-Tool-Based-Introduction-with-Python/Wilson/p/book/9781032725215"><img src="../sdxpy-cover.png" alt="Book cover" class="bookcover" /></a>
  
</p>

<div class="screen-reader-only">
  <a href="#printable">Skip to content</a>
</div>

<ol class="toc-chapters"><li><a href="../intro/">Introduction</a></li><li><a href="../oop/">Objects and Classes</a></li><li><a href="../dup/">Finding Duplicate Files</a></li><li><a href="../glob/">Matching Patterns</a></li><li><a href="../parse/">Parsing Text</a></li><li><a href="../test/">Running Tests</a></li><li><a href="../interp/">An Interpreter</a></li><li><a href="../func/">Functions and Closures</a></li><li><a href="../protocols/">Protocols</a></li><li><a href="../archive/">A File Archiver</a></li><li><a href="../check/">An HTML Validator</a></li><li><a href="../template/">A Template Expander</a></li><li><a href="../lint/">A Code Linter</a></li><li><a href="../layout/">Page Layout</a></li><li><a href="../perf/">Performance Profiling</a></li><li><a href="../persist/">Object Persistence</a></li><li><a href="../binary/">Binary Data</a></li><li><a href="../db/">A Database</a></li><li><a href="../build/">A Build Manager</a></li><li><a href="../pack/">A Package Manager</a></li><li><a href="../ftp/">Transferring Files</a></li><li><a href="../http/">Serving Web Pages</a></li><li><a href="../viewer/">A File Viewer</a></li><li><a href="../undo/">Undo and Redo</a></li><li><a href="../vm/">A Virtual Machine</a></li><li><a href="../debugger/">A Debugger</a></li><li><a href="../observe/">Observers</a></li><li><a href="../docgen/">Generating Documentation</a></li><li><a href="../search/">Search</a></li><li><a href="../compress/">File Compression</a></li><li><a href="../cache/">A File Cache</a></li><li><a href="../query/">A Query Builder</a></li><li><a href="../concur/">Concurrency</a></li><li><a href="../finale/">Conclusion</a></li></ol>
<ol class="toc-appendices"><li><a href="../bib/">Bibliography</a></li><li><a href="../bonus/">Bonus Material</a></li><li><a href="../syllabus/">Syllabus</a></li><li><a href="../license/">License</a></li><li><a href="../conduct/">Code of Conduct</a></li><li><a href="../contrib/">Contributing</a></li><li><a href="../glossary/">Glossary</a></li><li><a href="../colophon/">Colophon</a></li><li><a href="../contents/">Index</a></li></ol>


<p><a href="../sdxpy-examples.zip" type="application/zip">download examples</a></p>


<p><a href="https://github.com/gvwilson/sdxpy">GitHub repository</a></p>

      </div>
      <div id="printable" class="contents bordered">
	<main>
	  <div class="row notex">
  <div class="col-12 center">
    
      <h1>Finding Duplicate Files</h1>
    
  </div>
</div>

	  
<nav class="row-always notex">
  <div class="col-1 left">
    <a href="../oop/" title="previous" class="undecorated">&#8678;</a>
  </div>
  <div class="col-10 center">
    <a href="../" title="home" class="undecorated">&#9737;</a>
  </div>
  <div class="col-1 right">
    <a href="../glob/" title="next" class="undecorated">&#8680;</a>
  </div>
</nav>


	  <ul class="keypoints">
<li>A hash function creates a fixed-size value from an arbitrary sequence of bytes.</li>
<li>Use big-oh notation to estimate the running time of algorithms.</li>
<li>The output of a hash function is deterministic but not easy to predict.</li>
<li>A good hash function&rsquo;s output is evenly distributed.</li>
<li>A large cryptographic hash can be used to uniquely identify a file&rsquo;s contents.</li>
</ul>
	  <p class="terms">Terms defined: 
<a class="gl-ref" href="../glossary/#big_oh" markdown="1">big-oh notation</a>, <a class="gl-ref" href="../glossary/#binary_mode" markdown="1">binary mode</a>, <a class="gl-ref" href="../glossary/#bucket" markdown="1">bucket</a>, <a class="gl-ref" href="../glossary/#cryptographic_hash_function" markdown="1">cryptographic hash function</a>, <a class="gl-ref" href="../glossary/#hash_code" markdown="1">hash code</a>, <a class="gl-ref" href="../glossary/#hash_collision" markdown="1">collision (in hashing)</a>, <a class="gl-ref" href="../glossary/#hash_function" markdown="1">hash function</a>, <a class="gl-ref" href="../glossary/#hexadecimal" markdown="1">hexadecimal</a>, <a class="gl-ref" href="../glossary/#sha256" markdown="1">SHA-256 (hash function)</a>, <a class="gl-ref" href="../glossary/#streaming_api" markdown="1">streaming API</a>, <a class="gl-ref" href="../glossary/#time_complexity" markdown="1">time complexity</a>
</p>
	  <p>Suppose we want to find duplicated files,
such as extra copies of photos or data sets.
People often rename files,
so we must compare their contents,
but this will be slow if we have a lot of files.</p>
<p>We can estimate how slow &ldquo;slow&rdquo; will be with a simple calculation.
\( N \) objects can be paired in \( N(N-1) \) ways.
If we remove duplicate pairings
(i.e., if we count A-B and B-A as one pair)
then there are \( N(N-1)/2 = (N^2 - N)/2 \) distinct pairs.
As \( N \) gets large,
this value is approximately proportional to \( N^2 \).
A computer scientist would say that
the <a class="gl-ref" href="../glossary/#time_complexity" markdown="1">time complexity</a> of our algorithm is \( O(N^2) \),
which is pronounced &ldquo;<a class="gl-ref" href="../glossary/#big_oh" markdown="1">big-oh</a> of N squared&rdquo;.
In simpler terms,
when the number of files doubles,
the running time roughly quadruples,
which means the time per file increases as the number of files increases.</p>
<p>Slowdown like this is often unavoidable,
but in our case there&rsquo;s a better way.
If we generate a shorter identifier for each file
that depends only on the bytes it contains,
we can group together the files that have the same identifier
and only compare the files within a group.
This approach is faster because we only do the expensive byte-by-byte comparison
on files that <em>might</em> be equal.
And as we&rsquo;ll see,
if we are very clever about how we generate identifiers
then we can avoid byte-by-byte comparisons entirely.</p>
<h2 id="dup-start">Getting Started</h2>
<p>We&rsquo;ll start by implementing the inefficient \( N^2 \) approach
so that we can compare our later designs to it.
The short program below takes a list of filenames from the command line,
finds duplicates,
and prints the matches:</p>
<div class="language-py" title="brute_force_1.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">find_duplicates</span><span class="p">(</span><span class="n">filenames</span><span class="p">):</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">left</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">right</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">same_bytes</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
                <span class="n">matches</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">matches</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">duplicates</span> <span class="o">=</span> <span class="n">find_duplicates</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span> <span class="ow">in</span> <span class="n">duplicates</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
</code></pre></div>
</div>
<p>This program uses a function called <code>same_bytes</code>
that reads two files and compares them byte by byte:</p>
<div class="language-py" title="brute_force_1.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">same_bytes</span><span class="p">(</span><span class="n">left_name</span><span class="p">,</span> <span class="n">right_name</span><span class="p">):</span>
    <span class="n">left_bytes</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">left_name</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">right_bytes</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">right_name</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">left_bytes</span> <span class="o">==</span> <span class="n">right_bytes</span>
</code></pre></div>
</div>
<p class="continue">Notice that the files are opened in <a class="gl-ref" href="../glossary/#binary_mode" markdown="1">binary mode</a>
using <code>"rb"</code> instead of the usual <code>"r"</code>.
As we&rsquo;ll see in <a href="../binary/">Chapter&nbsp;17</a>,
this tells Python to read the bytes exactly as they are
rather than trying to convert them to characters.</p>
<p>To test this program and the others we&rsquo;re about to write,
we create a <code>tests</code> directory with six files:</p>
<table>
<thead>
<tr>
<th>Filename</th>
<th><code>a1.txt</code></th>
<th><code>a2.txt</code></th>
<th><code>a3.txt</code></th>
<th><code>b1.txt</code></th>
<th><code>b2.txt</code></th>
<th><code>c1.txt</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Content</td>
<td><code>aaa</code></td>
<td><code>aaa</code></td>
<td><code>aaa</code></td>
<td><code>bb</code></td>
<td><code>bb</code></td>
<td><code>c</code></td>
</tr>
</tbody>
</table>
<p>We expect the three <code>a</code> files and the two <code>b</code> files to be reported as duplicates.
There&rsquo;s no particular reason for these tests—we just have to start somewhere.
Our first test looks like this:</p>
<div class="language-sh" title="brute_force_1.sh">
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>brute_force_1.py<span class="w"> </span>tests/*.txt
</code></pre></div>
</div>
<div class="language-out" title="brute_force_1.out">
<div class="highlight"><pre><span></span><code>tests/a1.txt tests/a1.txt
tests/a1.txt tests/a2.txt
tests/a1.txt tests/a3.txt
tests/a2.txt tests/a1.txt
tests/a2.txt tests/a2.txt
tests/a2.txt tests/a3.txt
tests/a3.txt tests/a1.txt
tests/a3.txt tests/a2.txt
tests/a3.txt tests/a3.txt
tests/b1.txt tests/b1.txt
tests/b1.txt tests/b2.txt
tests/b2.txt tests/b1.txt
tests/b2.txt tests/b2.txt
tests/c1.txt tests/c1.txt
</code></pre></div>
</div>
<p>Our program&rsquo;s output is correct but not useful:
every file is reported as being identical to itself,
and every match of different files is reported twice.
Let&rsquo;s fix the nested loop in <code>find_duplicates</code>
so that we only check potentially differing pairs once
(<a class="fig-ref" href="../dup/#dup-triangle">Figure&nbsp;3.1</a>):</p>
<div class="language-py" title="brute_force_2.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">find_duplicates</span><span class="p">(</span><span class="n">filenames</span><span class="p">):</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i_left</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">)):</span>
        <span class="n">left</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">[</span><span class="n">i_left</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i_right</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i_left</span><span class="p">):</span>
            <span class="n">right</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">[</span><span class="n">i_right</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">same_bytes</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
                <span class="n">matches</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">matches</span>
</code></pre></div>
</div>
<figure id="dup-triangle">
<img src="./triangle.svg" alt="Looping over distinct combinations"/>
<figcaption>Figure&nbsp;3.1: Scoping the inner loop to produce unique combinations.</figcaption>
</figure>

<h2 id="dup-group">Hashing Files</h2>
<p>Instead of comparing every file against every other,
let&rsquo;s process each file once to produce a short identifier
that depends only on the file&rsquo;s contents
and then only compare files that have the same identifier,
i.e.,
that <em>might</em> be equal.
If files are evenly divided into \( g \) groups
then each group will contain roughly \( N/g \) files,
so the total work will be roughly \( O(g(N/g)^2) \)
(i.e., \( g \) groups times \( (N/g)^2 \) comparisons within each group).
Simplifying,
this is \( N^2/g \),
so as the number of groups grows,
the overall running time should decrease
(<a class="fig-ref" href="../dup/#dup-hash-group">Figure&nbsp;3.2</a>).</p>
<figure id="dup-hash-group">
<img src="./hash_group.svg" alt="Grouping by hash code"/>
<figcaption>Figure&nbsp;3.2: Grouping by hash code reduces comparisons from 15 to 4.</figcaption>
</figure>

<p>We can construct IDs for files using a <a class="gl-ref" href="../glossary/#hash_function" markdown="1">hash function</a>
to produce a <a class="gl-ref" href="../glossary/#hash_code" markdown="1">hash code</a>.
Since bytes are just numbers,
we can create a very simple hash function by adding up the bytes in a file
and taking the remainder modulo some number:</p>
<div class="language-py" title="naive_hash.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">naive_hash</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">%</span> <span class="mi">13</span>
</code></pre></div>
</div>
<p>Here&rsquo;s a quick test that calculates the hash code for
successively longer substrings of the word <code>"hashing"</code>:</p>
<div class="language-py" title="naive_hash.py">
<div class="highlight"><pre><span></span><code>    <span class="n">example</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="s2">&quot;hashing&quot;</span><span class="p">,</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">substring</span> <span class="o">=</span> <span class="n">example</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">hash</span> <span class="o">=</span> <span class="n">naive_hash</span><span class="p">(</span><span class="n">substring</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">hash</span><span class="si">:</span><span class="s2">2</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">substring</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="language-out" title="naive_hash.out">
<div class="highlight"><pre><span></span><code> 0 b&#39;h&#39;
 6 b&#39;ha&#39;
 4 b&#39;has&#39;
 4 b&#39;hash&#39;
 5 b&#39;hashi&#39;
11 b&#39;hashin&#39;
10 b&#39;hashing&#39;
</code></pre></div>
</div>
<p>The output seems random,
but is it?
As a more stringent test,
let&rsquo;s try hashing every line of text in
the <a href="https://www.gutenberg.org/">Project Gutenberg</a> version of the novel <em>Dracula</em>
and plot the distribution (<a class="fig-ref" href="../dup/#dup-naive-dracula">Figure&nbsp;3.3</a>).</p>
<figure id="dup-naive-dracula">
<img src="./naive_dracula.svg" alt="Hash codes of <em>Dracula</em>"/>
<figcaption>Figure&nbsp;3.3: Distribution of hash codes per line in <em>Dracula</em>.</figcaption>
</figure>

<p>Most of the <a class="gl-ref" href="../glossary/#bucket" markdown="1">buckets</a> are approximately the same height,
but why is there a peak at zero?
Our big-oh estimate of how efficient our algorithm would be
depended on files being distributed evenly between groups;
if that&rsquo;s not the case,
our code won&rsquo;t be as fast as we hoped.</p>
<p>After a bit of digging,
it turns out that
the text file we&rsquo;re processing uses a blank line to separate paragraphs.
These hash to zero,
so the peak reflects an unequal distribution in our data.
If we plot the distribution of hash codes of <em>unique</em> lines,
the result is more even (<a class="fig-ref" href="../dup/#dup-naive-dracula-unique">Figure&nbsp;3.4</a>).</p>
<figure id="dup-naive-dracula-unique">
<img src="./naive_dracula_unique.svg" alt="Hash codes of unique lines of <em>Dracula</em>"/>
<figcaption>Figure&nbsp;3.4: Distribution of hash codes per unique line in <em>Dracula</em>.</figcaption>
</figure>

<p>Hashing is a tremendously powerful tool:
for example,
Python&rsquo;s dictionaries hash their keys to make lookup fast.
Now that we can hash files,
we can build a dictionary with hash codes as keys
and sets of filenames as values.
The code that does this is shown below;
each time it calculates a hash code,
it checks to see if that value has been seen before.
If not,
it creates a new entry in the <code>groups</code> dictionary
with the hash code as its key
and an empty set as a value.
It can then be sure that there&rsquo;s a set to add the filename to:</p>
<div class="language-py" title="grouped.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">find_groups</span><span class="p">(</span><span class="n">filenames</span><span class="p">):</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">hash_code</span> <span class="o">=</span> <span class="n">naive_hash</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">hash_code</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">:</span>
            <span class="n">groups</span><span class="p">[</span><span class="n">hash_code</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">groups</span><span class="p">[</span><span class="n">hash_code</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">groups</span>
</code></pre></div>
</div>
<p>We can now re-use most of the code we wrote earlier
to find duplicates within each group:</p>
<div class="language-py" title="grouped.py">
<div class="highlight"><pre><span></span><code>    <span class="n">groups</span> <span class="o">=</span> <span class="n">find_groups</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">for</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">groups</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="n">duplicates</span> <span class="o">=</span> <span class="n">find_duplicates</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">filenames</span><span class="p">))</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span> <span class="ow">in</span> <span class="n">duplicates</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="language-out" title="grouped.out">
<div class="highlight"><pre><span></span><code>tests/a2.txt tests/a1.txt
tests/a3.txt tests/a1.txt
tests/a3.txt tests/a2.txt
tests/b1.txt tests/b2.txt
</code></pre></div>
</div>
<h2 id="dup-hash">Better Hashing</h2>
<p>Let&rsquo;s go back to the formula \( O(N^2/g) \)
that tells us how much work we have to do
if we have divided \( N \) files between \( g \) groups.
If we have exactly as many groups as files—i.e.,
if \( g \) is equal to \( N \)—then
the work to process \( N \) files would be \( O(N^2/N) = O(N) \),
which means that the work will be proportional to the number of files.
We have to read each file at least once anyway,
so we can&rsquo;t possibly do better than this,
but how can we ensure that each unique file winds up in its own group?</p>
<p>The answer is to use a
<a class="gl-ref" href="../glossary/#cryptographic_hash_function" markdown="1">cryptographic hash function</a>.
The output of such a function is completely deterministic:
given the same bytes in the same order,
it will always produce the same output.
However,
the output is distributed like a uniform random variable:
each possible output is equally likely,
which ensures that files will be evenly distributed between groups.</p>
<p>Cryptographic hash functions are hard to write,
and it&rsquo;s very hard to prove that a particular algorithm has the properties we require.
We will therefore use a function from Python&rsquo;s <a href="https://docs.python.org/3/library/hashlib.html">hashing module</a>
that implements the <a class="gl-ref" href="../glossary/#sha256" markdown="1">SHA-256</a> hashing algorithm.
Given some bytes as input,
this function produces a 256-bit hash,
which is normally written as a 64-character <a class="gl-ref" href="../glossary/#hexadecimal" markdown="1">hexadecimal</a> string.
This uses the letters A-F (or a-f) to represent the digits from 10 to 15,
so that (for example) <code>3D5</code> is \((3×16^2)+(13×16^1)+(5×16^0)\), or 981 in decimal:</p>
<div class="language-py" title="using_sha256.py">
<div class="highlight"><pre><span></span><code>    <span class="n">example</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="s2">&quot;hash&quot;</span><span class="p">,</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">substring</span> <span class="o">=</span> <span class="n">example</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">hash</span> <span class="o">=</span> <span class="n">sha256</span><span class="p">(</span><span class="n">substring</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">substring</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="nb">hash</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="language-out" title="using_sha256.out">
<div class="highlight"><pre><span></span><code>b&#39;h&#39;
aaa9402664f1a41f40ebbc52c9993eb66aeb366602958fdfaa283b71e64db123
b&#39;ha&#39;
8693873cd8f8a2d9c7c596477180f851e525f4eaf55a4f637b445cb442a5e340
b&#39;has&#39;
9150c74c5f92d51a92857f4b9678105ba5a676d308339a353b20bd38cd669ce7
b&#39;hash&#39;
d04b98f48e8f8bcc15c6ae5ac050801cd6dcfd428fb5f9e65c4e16e7807340fa
</code></pre></div>
</div>
<div class="callout">
<h3>The Birthday Problem</h3>
<p>The odds that two people share a birthday are 1/365 (ignoring February 29).
The odds that they <em>don&rsquo;t</em> are therefore \( 364/365 \).
When we add a third person,
the odds that they don&rsquo;t share a birthday
with either of the preceding two people are \( 363/365 \),
so the overall odds that nobody shares a birthday are \( (364/365)×(363/365) \).
If we keep going,
there&rsquo;s a 50% chance of two people sharing a birthday in a group of just 23 people,
and a 99.9% chance with 70 people.</p>
<p>The same math can tell us how many files we need to hash
before there&rsquo;s a 50% chance of a <a class="gl-ref" href="../glossary/#hash_collision" markdown="1">collision</a> with a 256-bit hash.
According to <a href="https://en.wikipedia.org/wiki/Birthday_problem">Wikipedia</a>,
the answer is approximately \( 4{\times}10^{38} \) files.
We&rsquo;re willing to take that risk.</p>
</div>
<p>Using this library function makes our duplicate file finder much shorter:</p>
<div class="language-py" title="dup.py">
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hashlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">sha256</span>

<span class="k">def</span><span class="w"> </span><span class="nf">find_groups</span><span class="p">(</span><span class="n">filenames</span><span class="p">):</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">hash_code</span> <span class="o">=</span> <span class="n">sha256</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">hash_code</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">:</span>
            <span class="n">groups</span><span class="p">[</span><span class="n">hash_code</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">groups</span><span class="p">[</span><span class="n">hash_code</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">groups</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="n">find_groups</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">for</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">groups</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">filenames</span><span class="p">)))</span>
</code></pre></div>
</div>
<div class="language-sh" title="dup.sh">
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>dup.py<span class="w"> </span>tests/*.txt
</code></pre></div>
</div>
<p>More importantly,
our new approach scales to very large sets of files:
as explained above,
we only have to look at each file once,
so the running time is as good as it possibly can be.</p>
<h2 id="dup-summary">Summary</h2>
<p><a class="fig-ref" href="../dup/#dup-concept-map">Figure&nbsp;3.5</a> summarizes the key ideas in this chapter,
the most important of which is that some algorithms are intrinsically better than others.</p>
<figure id="dup-concept-map" class="here">
<img src="./concept_map.svg" alt="Concept map for finding duplicate files"/>
<figcaption>Figure&nbsp;3.5: Concept map for duplicate file detection with hashing.</figcaption>
</figure>

<h2 id="dup-exercises">Exercises</h2>
<h3 class="exercise">Odds of Collision</h3>
<p>If hashes were only 2 bits long,
then the chances of collision with each successive file
assuming no previous collision are:</p>
<table>
<thead>
<tr>
<th>Number of Files</th>
<th>Odds of Collision</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0%</td>
</tr>
<tr>
<td>2</td>
<td>25%</td>
</tr>
<tr>
<td>3</td>
<td>50%</td>
</tr>
<tr>
<td>4</td>
<td>75%</td>
</tr>
<tr>
<td>5</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p class="continue">A colleague of yours says this means that if we hash four files,
there&rsquo;s only a 75% chance of any collision occurring.
What are the actual odds?</p>
<h3 class="exercise">Streaming I/O</h3>
<p>A <a class="gl-ref" href="../glossary/#streaming_api" markdown="1">streaming API</a> delivers data one piece at a time
rather than all at once.
Read the documentation for the <code>update</code> method of hashing objects
in Python&rsquo;s <a href="https://docs.python.org/3/library/hashlib.html">hashing module</a>
and rewrite the duplicate finder from this chapter
to use it.</p>
<h3 class="exercise">Big Oh</h3>
<p><a href="../intro/">Chapter&nbsp;1</a> said that as the number of components in a system grows,
the complexity of the system increases rapidly.
How fast is &ldquo;rapidly&rdquo; in big-oh terms?</p>
<h3 class="exercise">The <code>hash</code> Function</h3>
<ol>
<li>
<p>Read the documentation for Python&rsquo;s built-in <code>hash</code> function.</p>
</li>
<li>
<p>Why do <code>hash(123)</code> and <code>hash("123")</code> work when <code>hash([123])</code> <span class="ix-entry" ix-key="raise" markdown="1">raises</span> an exception?</p>
</li>
</ol>
<h3 class="exercise">How Good Is SHA-256?</h3>
<ol>
<li>
<p>Write a function that calculates the SHA-256 hash code
    of each unique line of a text file.</p>
</li>
<li>
<p>Convert the hex digests of those hash codes to integers.</p>
</li>
<li>
<p>Plot a histogram of those integer values with 20 bins.</p>
</li>
<li>
<p>How evenly distributed are the hash codes?
    How does the distribution change as you process larger files?</p>
</li>
</ol>
	</main>
	<footer>
  © 2025 <a href="https://third-bit.com/">Greg Wilson</a>
  &middot;
  <a href="../">home</a>
  &middot;
  <a href="https://github.com/gvwilson/sdxpy">repository</a>
  &middot;
  <a href="../license/">license</a>
  &middot;
  <a href="mailto:gvwilson@third-bit.com">contact</a>
</footer>

      </div>
    </div>
  </body>
</html>
