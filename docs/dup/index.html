<!DOCTYPE html>
<html lang="en">
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="repo" content="https://github.com/gvwilson/sd4ds">
  <meta name="build_date" content="2023-06-30">
  <meta name="template" content="default">
  <meta name="major" content="Chapter 2">
  <meta name="has_slides" content="true">
  <link rel="icon" type="image/x-icon" href="../favicon.ico">
  <link rel="stylesheet" href="../mccole.css">
  <link rel="stylesheet" href="../tango.css">
  <script defer data-domain="third-bit.com" src="https://plausible.io/js/plausible.js"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['\\(', '\\)']]
      }
    };
  </script>
  <script
    type="text/javascript"
    id="MathJax-script"
    async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <script defer src="../mccole.js"></script>
  <title>Software Design for Data Scientists: Finding Duplicate Files</title>
</head>

  <body>
    <div class="row">
      <div class="sidebar">
        <p>
  
  <img src="../logo.svg" alt="site logo" class="logo" />
  <a href="../">Software Design for Data Scientists</a>
  
</p>
<ol class="toc-chapter">
  
  <li>
    <a href="../intro/">
      Introduction
    </a>
  </li>
  
  <li>
    <a href="../dup/">
      <strong>Finding Duplicate Files</strong>
    </a>
  </li>
  
  <li>
    <a href="../glob/">
      Matching Patterns
    </a>
  </li>
  
  <li>
    <a href="../parse/">
      Parsing Text
    </a>
  </li>
  
  <li>
    <a href="../test/">
      Running Tests
    </a>
  </li>
  
  <li>
    <a href="../interp/">
      An Interpreter
    </a>
  </li>
  
  <li>
    <a href="../oop/">
      Objects and Classes
    </a>
  </li>
  
  <li>
    <a href="../func/">
      Functions and Closures
    </a>
  </li>
  
  <li>
    <a href="../mock/">
      Mocks, Protocols, and Decorators
    </a>
  </li>
  
  <li>
    <a href="../archive/">
      A File Archiver
    </a>
  </li>
  
  <li>
    <a href="../check/">
      An HTML Validator
    </a>
  </li>
  
  <li>
    <a href="../template/">
      A Template Expander
    </a>
  </li>
  
  <li>
    <a href="../lint/">
      A Code Linter
    </a>
  </li>
  
  <li>
    <a href="../layout/">
      Page Layout
    </a>
  </li>
  
  <li>
    <a href="../perf/">
      Performance Profiling
    </a>
  </li>
  
  <li>
    <a href="../persist/">
      Object Persistence
    </a>
  </li>
  
  <li>
    <a href="../binary/">
      Binary Data
    </a>
  </li>
  
  <li>
    <a href="../db/">
      A Database
    </a>
  </li>
  
  <li>
    <a href="../build/">
      A Build Manager
    </a>
  </li>
  
  <li>
    <a href="../pack/">
      A Package Manager
    </a>
  </li>
  
  <li>
    <a href="../ftp/">
      Transferring Files
    </a>
  </li>
  
  <li>
    <a href="../http/">
      Serving Web Pages
    </a>
  </li>
  
  <li>
    <a href="../viewer/">
      A File Viewer
    </a>
  </li>
  
  <li>
    <a href="../undo/">
      Undo and Redo
    </a>
  </li>
  
  <li>
    <a href="../vm/">
      A Virtual Machine
    </a>
  </li>
  
  <li>
    <a href="../debugger/">
      A Debugger
    </a>
  </li>
  
  <li>
    <a href="../finale/">
      Conclusion
    </a>
  </li>
  
</ol>
<ol class="toc-appendix">
  
  <li>
    <a href="../bib/">
      Bibliography
    </a>
  </li>
  
  <li>
    <a href="../bonus/">
      Bonus Material
    </a>
  </li>
  
  <li>
    <a href="../syllabus/">
      Syllabus
    </a>
  </li>
  
  <li>
    <a href="../slides/">
      Slides
    </a>
  </li>
  
  <li>
    <a href="../license/">
      License
    </a>
  </li>
  
  <li>
    <a href="../conduct/">
      Code of Conduct
    </a>
  </li>
  
  <li>
    <a href="../contrib/">
      Contributing
    </a>
  </li>
  
  <li>
    <a href="../glossary/">
      Glossary
    </a>
  </li>
  
  <li>
    <a href="../credits/">
      Credits
    </a>
  </li>
  
  <li>
    <a href="../contents/">
      Index
    </a>
  </li>
  
</ol>

<p><a href="../sd4ds-examples.zip" type="application/zip">download examples</a></p>


      </div>
      <div id="printable" class="contents bordered">
        <main>
          
  <h1>Chapter 2: Finding Duplicate Files</h1>


          
<div class="draft notex">
  <p>DRAFT</p>
  <p>
    <em>Please use section heading links to submit feedback.</em>
  </p>
</div>


          
  
  <ul class="syllabus">
  
  <li markdown="1">A hash function creates a fixed-size value from an arbitrary sequence of bytes.</li>
  
  <li markdown="1">Use big-oh notation to estimate the running time of algorithms.</li>
  
  <li markdown="1">The output of a hash function is deterministic but not predictable.</li>
  
  <li markdown="1">A good hash function's output is evenly distributed.</li>
  
  <li markdown="1">A cryptographic hash function generates a unique identifier for a file's contents.</li>
  
  </ul>
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


          
<p class="definitions">
  Terms defined: <a class="gl-ref" href="../glossary/#big_oh" markdown="1">big-oh notation</a>, <a class="gl-ref" href="../glossary/#binary_mode" markdown="1">binary mode</a>, <a class="gl-ref" href="../glossary/#hash_collision" markdown="1">collision (in hashing)</a>, <a class="gl-ref" href="../glossary/#cryptographic_hash_function" markdown="1">cryptographic hash function</a>, <a class="gl-ref" href="../glossary/#hash_code" markdown="1">hash code</a>, <a class="gl-ref" href="../glossary/#hash_function" markdown="1">hash function</a>, <a class="gl-ref" href="../glossary/#hexadecimal" markdown="1">hexadecimal</a>, <a class="gl-ref" href="../glossary/#sha256" markdown="1">SHA-256 (hash function)</a>, <a class="gl-ref" href="../glossary/#streaming_api" markdown="1">streaming API</a>, <a class="gl-ref" href="../glossary/#time_complexity" markdown="1">time complexity</a>
</p>


          <div class="page-toc"></div>
          <p>Suppose we want to find duplicated files,
such as extra copies of photos or data sets.
We can&rsquo;t rely on the files&rsquo; names;
instead,
we need to compare their contents,
but this will be slow for large files.</p>
<p>A better approach is to generate a shorter identifier for each file
that depends only on the bytes it contains,
then group files with the same identifier and compare those.
This approach is faster because we only compare files that might be equal,
and as we&rsquo;ll see,
we can generate identifiers so that if two files have the same one,
they&rsquo;re (almost) guaranteed to have the same content.</p>
<h2 id="dup-start">Section 2.1: Getting Started</h2>
<p>We&rsquo;ll start by implementing the brute force approach
so that we can compare sophisticated designs to it.
The short program below takes a list of filenames from the command line,
finds duplicates,
and prints the matches:</p>
<div class="code-sample lang-py" title="brute_force_1.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">find_duplicates</span><span class="p">(</span><span class="n">filenames</span><span class="p">):</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">left</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">right</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">same_bytes</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
                <span class="n">matches</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">matches</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">duplicates</span> <span class="o">=</span> <span class="n">find_duplicates</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span> <span class="ow">in</span> <span class="n">duplicates</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
</code></pre></div>
</div>
<p>The function <code>same_bytes</code> reads two files and compares them byte by byte:</p>
<div class="code-sample lang-py" title="brute_force_1.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">same_bytes</span><span class="p">(</span><span class="n">left_name</span><span class="p">,</span> <span class="n">right_name</span><span class="p">):</span>
    <span class="n">left_bytes</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">left_name</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">right_bytes</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">right_name</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">left_bytes</span> <span class="o">==</span> <span class="n">right_bytes</span>
</code></pre></div>
</div>
<p class="continue">Notice that the files are opened in <a class="gl-ref" href="../glossary/#binary_mode" markdown="1">binary mode</a>
using <code>"rb"</code> instead of the usual <code>"r"</code>.
As we&rsquo;ll see in <a class="x-ref" href="../binary/">Chapter 17</a>,
this tells Python to read the bytes as they are
rather than trying to convert them to characters.</p>
<p>To test this program and the others we&rsquo;re about to write,
we create a <code>tests</code> directory with six files:</p>
<table>
<thead>
<tr>
<th><code>a1.txt</code></th>
<th><code>a2.txt</code></th>
<th><code>a3.txt</code></th>
<th><code>b1.txt</code></th>
<th><code>b2.txt</code></th>
<th><code>c1.txt</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>aaa</td>
<td>aaa</td>
<td>aaa</td>
<td>bb</td>
<td>bb</td>
<td>c</td>
</tr>
</tbody>
</table>
<p>We expect the three <code>a</code> files and the two <code>b</code> files to be reported as duplicates.
There&rsquo;s no particular reason for these tests—we just have to start somewhere.
We run our program like this:</p>
<div class="code-sample lang-sh" title="brute_force_1.sh">
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>brute_force_1.py<span class="w"> </span>tests/*.txt
</code></pre></div>
</div>
<div class="code-sample lang-out" title="brute_force_1.out">
<div class="highlight"><pre><span></span><code>tests/a1.txt tests/a1.txt
tests/a1.txt tests/a2.txt
tests/a1.txt tests/a3.txt
tests/a2.txt tests/a1.txt
tests/a2.txt tests/a2.txt
tests/a2.txt tests/a3.txt
tests/a3.txt tests/a1.txt
tests/a3.txt tests/a2.txt
tests/a3.txt tests/a3.txt
tests/b1.txt tests/b1.txt
tests/b1.txt tests/b2.txt
tests/b2.txt tests/b1.txt
tests/b2.txt tests/b2.txt
tests/c1.txt tests/c1.txt
</code></pre></div>
</div>
<p>The output is correct but not useful:
every file is reported as being identical to itself,
and every match of different files is reported twice.
Let&rsquo;s fix the nested loop in <code>find_duplicates</code>
so that we only check potentially differing pairs once
(<a class="fig-ref" href="../dup/#dup-triangle">Figure 2.1</a>):</p>
<div class="code-sample lang-py" title="brute_force_2.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">find_duplicates</span><span class="p">(</span><span class="n">filenames</span><span class="p">):</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i_left</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">)):</span>
        <span class="n">left</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">[</span><span class="n">i_left</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i_right</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i_left</span><span class="p">):</span>
            <span class="n">right</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">[</span><span class="n">i_right</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">same_bytes</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
                <span class="n">matches</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">matches</span>
</code></pre></div>
</div>
<figure id="dup-triangle">
<img src="./triangle.svg" alt="Looping over distinct combinations"/>
<figcaption markdown="1">Figure 2.1: Scoping the inner loop to produce unique combinations.</figcaption>
</figure>

<p>How much work does our revised program do?
\( N \) objects can be paired in \( N(N-1)/2 \) ways,
so for large \( N \) the work is proportional to \( N^2 \).
A computer scientist would say that
the <a class="gl-ref" href="../glossary/#time_complexity" markdown="1">time complexity</a> of our algorithm is \( O(N^2) \),
which is pronounced &ldquo;<a class="gl-ref" href="../glossary/#big_oh" markdown="1">big-oh</a> of N squared&rdquo;.
If the number of files doubles,
the running time roughly quadruples,
which means means that the time per file increases as the number of files increases.
Slowdown like this is often unavoidable,
but in this case there&rsquo;s a better way.</p>
<h2 id="dup-group">Section 2.2: Hashing Files</h2>
<p>Instead of comparing every file against every other,
let&rsquo;s process each file once to produce a short identifier
and only compare files with the same identifier
(<a class="fig-ref" href="../dup/#dup-hash-group">Figure 2.2</a>).
If there are \( g \) files in each group,
the work will be roughly \( O(g(N/g)^2) \)
(i.e., \( g \) groups times \( (N/g)^2 \) comparisons within each group).
As the number of groups gets larger,
the number of files in each group will hopefully get smaller,
and the overall running time will decrease
<em>if</em> the files are evenly distributed between the groups.</p>
<figure id="dup-hash-group">
<img src="./hash_group.svg" alt="Grouping by hash code"/>
<figcaption markdown="1">Figure 2.2: Grouping by hash code reduces comparisons from 15 to 4.</figcaption>
</figure>

<p>We can construct IDs for files using a <a class="gl-ref" href="../glossary/#hash_function" markdown="1">hash function</a>
to produce a <a class="gl-ref" href="../glossary/#hash_code" markdown="1">hash code</a>.
Since bytes are just numbers,
we can create a very simple hash function by adding up the bytes in a file
and taking the remainder modulo some number:</p>
<div class="code-sample lang-py" title="naive_hash.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">naive_hash</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">%</span> <span class="mi">13</span>
</code></pre></div>
</div>
<p>Here&rsquo;s a quick test that calculates the hash code for
successively longer substrings of the word <code>"hashing"</code>:</p>
<div class="code-sample lang-py" title="naive_hash.py">
<div class="highlight"><pre><span></span><code>    <span class="n">example</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="s2">&quot;hashing&quot;</span><span class="p">,</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">substring</span> <span class="o">=</span> <span class="n">example</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">hash</span> <span class="o">=</span> <span class="n">naive_hash</span><span class="p">(</span><span class="n">substring</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">hash</span><span class="si">:</span><span class="s2">2</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">substring</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="code-sample lang-out" title="naive_hash.out">
<div class="highlight"><pre><span></span><code> 0 b&#39;h&#39;
 6 b&#39;ha&#39;
 4 b&#39;has&#39;
 4 b&#39;hash&#39;
 5 b&#39;hashi&#39;
11 b&#39;hashin&#39;
10 b&#39;hashing&#39;
</code></pre></div>
</div>
<p>The output seems random,
but is it?
As a more stringent test,
let&rsquo;s try hashing every line of text in
<a href="https://www.gutenberg.org/">Project Gutenberg</a>&lsquo;s version of the novel <em>Dracula</em>
and plot the distribution (<a class="fig-ref" href="../dup/#dup-naive-dracula">Figure 2.3</a>).</p>
<figure id="dup-naive-dracula">
<img src="./naive_dracula.svg" alt="Hash codes of <em>Dracula</em>"/>
<figcaption markdown="1">Figure 2.3: Distribution of hash codes per line in <em>Dracula</em>.</figcaption>
</figure>

<p>Is the histogram&rsquo;s peak at zero a flaw of some kind in our hash function?
After a bit of digging,
we realize that
the text file we&rsquo;re processing uses a blank line to separate paragraphs,
so the peak reflects a bias in our data.
If we plot the distribution of hash codes of <em>unique</em> lines,
the result is more even (<a class="fig-ref" href="../dup/#dup-naive-dracula-unique">Figure 2.4</a>).</p>
<figure id="dup-naive-dracula-unique">
<img src="./naive_dracula_unique.svg" alt="Hash codes of unique lines of <em>Dracula</em>"/>
<figcaption markdown="1">Figure 2.4: Distribution of hash codes per unique line in <em>Dracula</em>.</figcaption>
</figure>

<p>Now that we can hash files,
we can build a dictionary with hash codes as keys
and sets of files as values.
We do this using a common pattern
where if we haven&rsquo;t seen a particular key before,
we add it with an empty value,
then unilaterally add this file to that value
(in this case, a set):</p>
<div class="code-sample lang-py" title="grouped.py">
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">find_groups</span><span class="p">(</span><span class="n">filenames</span><span class="p">):</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">hash_code</span> <span class="o">=</span> <span class="n">naive_hash</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">hash_code</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">:</span>
            <span class="n">groups</span><span class="p">[</span><span class="n">hash_code</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">groups</span><span class="p">[</span><span class="n">hash_code</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">groups</span>
</code></pre></div>
</div>
<p>We can now re-use most of the code we wrote earlier
to find duplicates within each group:</p>
<div class="code-sample lang-py" title="grouped.py">
<div class="highlight"><pre><span></span><code>    <span class="n">groups</span> <span class="o">=</span> <span class="n">find_groups</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">for</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">groups</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="n">duplicates</span> <span class="o">=</span> <span class="n">find_duplicates</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">filenames</span><span class="p">))</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span> <span class="ow">in</span> <span class="n">duplicates</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="code-sample lang-out" title="grouped.out">
<div class="highlight"><pre><span></span><code>tests/a3.txt tests/a1.txt
tests/a2.txt tests/a1.txt
tests/a2.txt tests/a3.txt
tests/b2.txt tests/b1.txt
</code></pre></div>
</div>
<h2 id="dup-hash">Section 2.3: Better Hashing</h2>
<p>Let&rsquo;s go back to the formula \( O(g(N/g)^2) \)
that tells us how much work we have to do
if we have divided \( N \) files between \( g \) groups.
If \( g \) and \( N \) are equal—i.e.,
if we have exactly as many groups as files—then
the work to process \( N \) files would be \( O(N) \).
We have to read each file at least once,
so we can&rsquo;t possibly do better than this,
but how can we ensure that each unique file winds up in its own group?</p>
<p>The answer is to use a
<a class="gl-ref" href="../glossary/#cryptographic_hash_function" markdown="1">cryptographic hash function</a>.
The output is completely deterministic:
given the same bytes in the same order,
it will always produce the same output.
However,
its output is distributed like a uniform random variable,
and is unpredictable:
given a hash code,
there&rsquo;s no way to figure out what bytes would produce it
other than generating random strings of bytes and hashing them.</p>
<p>Cryptographic hash functions are hard to write—or rather,
it&rsquo;s very hard to prove that a particular algorithm has the properties we require.
We will therefore use a function from Python&rsquo;s <a href="https://docs.python.org/3/library/hashlib.html">hashing library</a>
that implements the <a class="gl-ref" href="../glossary/#sha256" markdown="1">SHA256</a> algorithm.
Given some bytes as input,
this function produces a 256-bit hash,
which is normally written as a 64-character <a class="gl-ref" href="../glossary/#hexadecimal" markdown="1">hexadecimal</a> string.
This uses the letters A-F (or a-f) to represent the digits from 10 to 15,
so that (for example) <code>3D5</code> is \((3×16^2)+(13×16^1)+(5×16^0)\), or 981 in decimal:</p>
<div class="code-sample lang-py" title="using_sha256.py">
<div class="highlight"><pre><span></span><code>    <span class="n">example</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="s2">&quot;hash&quot;</span><span class="p">,</span> <span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">example</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">substring</span> <span class="o">=</span> <span class="n">example</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">hash</span> <span class="o">=</span> <span class="n">sha256</span><span class="p">(</span><span class="n">substring</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">substring</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="nb">hash</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="code-sample lang-out" title="using_sha256.out">
<div class="highlight"><pre><span></span><code>b&#39;h&#39;
aaa9402664f1a41f40ebbc52c9993eb66aeb366602958fdfaa283b71e64db123
b&#39;ha&#39;
8693873cd8f8a2d9c7c596477180f851e525f4eaf55a4f637b445cb442a5e340
b&#39;has&#39;
9150c74c5f92d51a92857f4b9678105ba5a676d308339a353b20bd38cd669ce7
b&#39;hash&#39;
d04b98f48e8f8bcc15c6ae5ac050801cd6dcfd428fb5f9e65c4e16e7807340fa
</code></pre></div>
</div>
<div class="callout">
<h3>The Birthday Problem</h3>
<p>The odds that two people share a birthday are 1/365 (ignoring February 29).
The odds that they <em>don&rsquo;t</em> are therefore 364/365.
When we add a third person,
the odds that they don&rsquo;t share a birthday
with either of the preceding two people are 363/365,
so the overall odds that nobody shares a birthday are (364/365)×(363/365).
If we keep going,
there&rsquo;s a 50% chance of two people sharing a birthday in a group of just 23 people,
and a 99.9% chance with 70 people.</p>
<p>The same math can tell us how many files we need to hash
before there&rsquo;s a 50% chance of a <a class="gl-ref" href="../glossary/#hash_collision" markdown="1">collision</a> with a 256-bit hash.
According to <a href="https://en.wikipedia.org/wiki/Birthday_problem">Wikipedia</a>,
the answer is approximately \(4{\times}10^{38}\) files.
We&rsquo;re willing to take that risk…</p>
</div>
<p>Using this function makes our duplicate file finder much shorter:</p>
<div class="code-sample lang-py" title="dup.py">
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">hashlib</span> <span class="kn">import</span> <span class="n">sha256</span>

<span class="k">def</span> <span class="nf">find_groups</span><span class="p">(</span><span class="n">filenames</span><span class="p">):</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">hash_code</span> <span class="o">=</span> <span class="n">sha256</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">hash_code</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">:</span>
            <span class="n">groups</span><span class="p">[</span><span class="n">hash_code</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">groups</span><span class="p">[</span><span class="n">hash_code</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">groups</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="n">find_groups</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">for</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">groups</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">filenames</span><span class="p">)))</span>
</code></pre></div>
</div>
<div class="code-sample lang-sh" title="dup.sh">
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>dup.py<span class="w"> </span>tests/*.txt
</code></pre></div>
</div>
<div class="code-sample lang-out" title="dup.out">
<div class="highlight"><pre><span></span><code>tests/a1.txt, tests/a2.txt, tests/a3.txt
tests/b1.txt, tests/b2.txt
tests/c1.txt
</code></pre></div>
</div>
<p>More importantly,
our new approach scales to very large sets of files:
as explained above,
we only have to look at each file once,
so the running time is as good as it possibly can be.</p>
<h2 id="dup-summary">Section 2.4: Summary</h2>
<p>Hashing is a tremendously powerful tool:
Python&rsquo;s dictionaries hash their keys to make lookup fast,
and version control systems use it to determine
when two files or two revisions of a repository are the same or not
(<a class="x-ref" href="../archive/">Chapter 10</a>).</p>
<p>But our duplicate file finder is just a beginning.
<a class="x-ref" href="../glob/">Chapter 3</a> shows how we can find sets of files to compare;
<a class="x-ref" href="../test/">Chapter 5</a> and <a class="x-ref" href="../mock/">Chapter 9</a> build tools to test programs like this,
while <a class="x-ref" href="../lint/">Chapter 13</a> explores ways of checking that our programs follow style guidelines.</p>
<figure id="dup-concept-map">
<img src="./concept_map.svg" alt="Concept map for finding duplicate files"/>
<figcaption markdown="1">Figure 2.5: Concept map for duplicate file detection with hashing.</figcaption>
</figure>

<h2 id="dup-exercises">Section 2.5: Exercises</h2>
<h3 class="exercise">Odds of Collision</h3>
<p>If hashes were only 2 bits long,
then the chances of collision with each successive file
assuming no previous collision are:</p>
<table>
<thead>
<tr>
<th>Number of Files</th>
<th>Odds of Collision</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0%</td>
</tr>
<tr>
<td>2</td>
<td>25%</td>
</tr>
<tr>
<td>3</td>
<td>50%</td>
</tr>
<tr>
<td>4</td>
<td>75%</td>
</tr>
<tr>
<td>5</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>A colleague of yours says this means that if we hash four files,
there&rsquo;s only a 75% chance of any collision occurring.
What are the actual odds?</p>
<h3 class="exercise">Streaming I/O</h3>
<p><span class="fixme">FIXME streaming I/O exercise</span>
<a class="gl-ref" href="../glossary/#streaming_api" markdown="1">streaming API</a></p>
<h3 class="exercise">Big Oh</h3>
<p><span class="fixme">FIXME big oh exercise</span></p>
<h3 class="exercise">The <code>hash</code> Function</h3>
<ul>
<li>
<p>Read the documentation for Python&rsquo;s built-in <code>hash</code> function</p>
</li>
<li>
<p>Why do <code>hash(123)</code> and <code>hash("123")</code> work but <code>hash([123])</code> raise an exception?</p>
</li>
</ul>
<h3 class="exercise">How Good Is SHA256?</h3>
<ul>
<li>
<p>Write a function that calculate the SHA256 hash code
    of each unique line of a text file.</p>
</li>
<li>
<p>Convert the hex digests of those hash codes to integers.</p>
</li>
<li>
<p>Plot a histogram of those integer values with 20 bins.</p>
</li>
<li>
<p>How evenly distributed are the hash codes?
    How does the distribution change as you process larger files?</p>
</li>
</ul>
        </main>
      </div>
    </div>
  </body>
</html>
